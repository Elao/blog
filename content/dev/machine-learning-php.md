---
type:           "post"
title:          "Du machine learning avec PHP"
date:           "2020-05-06"
publishdate:    "2020-05-06"
draft:          false
slug:           "machine-learning-avec-php"
description:    "Du machine learning avec PHP."

thumbnail:      "/images/posts/thumbnails/pwa-general.jpg"
header_img:     "/images/posts/2016/pwa/pwa-general.jpg"
tags:           ["machine learning", "ia", "php"]
categories:     ["dev"]

author_username: "mcolin"

---

L'**intelligence artificielle** et le **machine learning** sont deux notions en vogue en ce moment mais assez abstraites pour beaucoup de d√©veloppeurs. Nous allons dymistifier un peu cela dans cet article et voir comment et pourquoi utiliser le **machine learning**.

N'√©tant moi m√™me pas sp√©cialiste, cet article est une introduction simple et basique au machine learning ainsi qu'un retour sur mes exp√©rimentation en la mati√®re avec **PHP** pour des probl√®matiques qui peuvent ce pos√© dans le monde du web. Il ne couvrira donc pas la totalit√© de ce qu'est et de ce que permet le **machine learning**.

## Le machine learning

Le **machine learning** est une branche de l'**intelligence artificielle** qui consiste √† nourrir un algorithme avec une quantit√© importante de donn√©es dans un domaine pr√©cis afin que celui ci en d√©termine des r√®gles lui permettant de r√©soudre un probl√®me dans ce m√™me domaine.

Cette phase d'ingestion de donn√©es est appel√© l'**apprentissage** ou l'**entrainement**. Il existe plusieurs types d'apprentissage :

* **Supervis√©** : on fourni les donn√©es d'exemple ainsi que les r√©ponses attendues
* **Non supervis√©** : on ne fourni que les donn√©es d'exemple, l'agorithme tir seul des conclusions √† partir des donn√©es
* **Semi-supervis√©** : seule une partie des donn√©es d'exemple est associ√©e √† une r√©ponse
* **Par remforcement** : similaire √† l'apprentissage non-suppervis√© mais on "r√©compense" la machine pour ses bonnes r√©ponses
* **Par transfert** : la machine se base sur les solutions √† des probl√®mes similaires pour trouver la r√©ponse

Gr√¢ce au **machine learning**, un ordinateur peut r√©soudre plusieurs types de probl√®mes, je vais vous parler de trois d'entre eux :

* **Classer** des √©l√©ments dans des groupes pr√©d√©finit, il s'agit de la **classification**
* Trouver une relations entre plusieurs variables afin d'en **pr√©dire** l'√©volution, il s'agit de la **r√©gression**
* **Regrouper** des √©l√©ments qui se ressemblent en groupes homog√®nes, il s'agit du **clustering**

L'une de difficult√© du machine learning est de d√©terminer quel type d'apprentissage et quel type d'algorithme correspond √† son probl√®me, puis de mod√®liser ses donn√©es pour correspondre aux besoins de l'algorithme.

## PHP ML

Etant moi m√™me d√©veloppeur **PHP**, j'ai souhait√© explorer une piste me permettant de rester dans l'√©cosyst√®me que je ma√Ætrise et me concentrer le **machine learning**.

[PHP ML](https://github.com/php-ai/php-ml) est une biblioth√®que permettant de faire du **machine learning avec PHP**. Certains algorithmes sont impl√©ment√©s directement en **PHP**, d'autres utilisent une biblioth√®que √©crit en C++, [libsvm](https://www.csie.ntu.edu.tw/~cjlin/libsvm/), pilot√© par **PHP ML**. Le binaire est fourni pour Windows, macOS et Linux, il n'y a rien a installer en plus et nous n'aurons qu'√† manipuler du **PHP**.

```
composer require php-ai/php-ml
```

Dans la suite de l'article, je vais d√©tailler quelques types de probl√®mes r√©solvables gr√¢ce au **machine learning**, lister quelques de cas d'usages concr√™ts dans le monde du web et pr√©senter un exemple avec **PHP ML**.

## La classification

**La classification** permet de classer des √©l√©ments dans des groupes. Il s'agit d'apprentissage supervis√©, on entra√Æne l'algorithme avec un jeu de donn√©es associant un grand nombre d'√©l√©ments exemples √† des groupes pr√©d√©finis. L'algorithme ainsi entrain√© pourra d√©terminer √† quel groupe appartient un nouvel √©l√©ment.

Concr√™ment, les taches de classification peuvent √™tre pr√©-mach√©s voir compl√®ment automatis√© gr√¢ce √† ce type d'algorithme.

Par exemple :

* D√©terminer la langue d'un texte
* D√©terminer si un message est positif ou n√©gatif
* Classer des articles dans des cat√©gories
* Classer des messages entre urgent et non urgent
* Classer des messages en spam

### Uses cases

Prenons l'exemple d'une application bancaire qui devrait classer les transactions en cat√©gories (restaurant, loisir, shopping, loyer, salaire, ...).

<figure>
  <img src="/images/posts/2020/machine-learning/classification-chart.svg" alt="" />
</figure>

Nous avons en entrer un fichier CSV comportant dans une premi√®re colonne le libell√© des transactions et dans une seconde colonne la cat√©gorie attendue. Plus vous aurez de donn√©es, plus votre algorithme aura des chances d'√™tre juste.

```csv
"label", "category"
"FACTURE(S) CARTE XXX DU 010113 APPLE ITUNES ST LUX 1,79EUR", "shopping"
"FACTURE(S) CARTE XXX DU 120114 CARREFOUR VILLE VILLEURBANNE", "food"
"FACTURE(S) CARTE XXX DU 190115 PAYPAL 0800 942 890", "shopping"
"VIREMENT RECU TIERS ELAO SARL ELAO - SAL012013", "wage"
"RETRAIT DAB 17/02/13 20H49 0398493 BNP PARIBAS LYON 2EME XXX", "withdrawals"
"PRELEVEMENT FREE TELECOM NUM 684936 ECH 01.04.13 REF FREE HAUTDEBIT", "multimedia"
```

Il faut tout d'abbord charger ces donn√©es :

{{< highlight php >}}
<?php
use Phpml\Dataset\CsvDataset;

$data = new CsvDataset('data.csv', 1);
{{< /highlight >}}

Ensuite, il faut modeliser ces donn√©es sous une forme compr√©hensible par l'algorithme (g√©n√©ralement des chiffres, des vecteurs, des matrices, ... bref, des maths üòÅ). Pour cela on va utiliser des *transformer*.

{{< highlight php >}}
<?php
use Phpml\FeatureExtraction\{TokenCountVectorizer,TfIdfTransformer,StopWords};
use Phpml\Tokenization\WordTokenizer;
use Phpml\Transformer;

$singleColumnTransformer = new class implements Transformer {
  public function fit(array $samples, ?array $targets = null): void { }
  public function transform(array &$samples, ?array &$targets = null): void {
    $samples = array_column($samples, 0);
  }
}

$transformers = [
    $singleColumnTransformer,
    new TokenCountVectorizer(new WordTokenizer(), StopWords::factory('French')),
    new TfIdfTransformer()
];
{{< /highlight >}}

Dans notre cas, c'est la pr√©sence de certains mots qui va nous indiquer la cat√©gorie de la transaction.

`$singleColumnTransformer` va extraire la premi√®re colonne de nos donn√©es, le libell√© des transactions.

Le `TokenCountVectorizer` va extraire tous les mots de nos libell√©s, hors stopwords, et compter leur occurence dans chaque libell√©.

Puis, le `TfIdfTransformer` va utiliser l'algorithme [TF-IDF](https://fr.wikipedia.org/wiki/TF-IDF) pour convertir cela en fr√©quence d'utilisation de chaque mot dans nos libell√©s.

> TF-IDF (term frequency‚Äìinverse document frequency), est une statistic num√©rique qui a pour but de refl√®ter √† quel point un mot est important pour un document dans une collection ou un corpus.

Maintenant que nos donn√©es sont pr√®tes, nous allons pouvoir choisir notre algorithme de classification et l'entrain√©.

**PHP-ML** fourni trois algorithmes :

* `Phpml\Classification\SVC`  qui est une configuration de [<abbr title="Support Vector Machine">SVM</abbr>](https://fr.wikipedia.org/wiki/Machine_%C3%A0_vecteurs_de_support) d√©di√© √† la classification
* `Phpml\Classification\NaiveBayes` qui utilise la [classification na√Øve bay√©sienne](https://fr.wikipedia.org/wiki/Classification_na%C3%AFve_bay%C3%A9sienne)
* `Phpml\Classification\KNearestNeighbors` qui utilise la [m√©thode des k plus proches voisins](https://fr.wikipedia.org/wiki/M%C3%A9thode_des_k_plus_proches_voisins)

En **machine learning**, il n'y a pas de meilleur algorithme dans l'absolut, l'efficacit√© de chacun d√©pend des donn√©es (type, quantit√© et qualit√©) et du probl√®me √† r√©soudre.

Commen√ßons avec `SVC` :

{{< highlight php >}}
<?php
use Phpml\Classification\SVC;
use Phpml\SupportVectorMachine\Kernel;

$estimator = new SVC();
$pipeline = new Pipeline($transformers, $estimator);
{{< /highlight >}}

On entraine tout d'abbord l'algorithme avec nos donn√©es :

{{< highlight php >}}
<?php
$pipeline->train($data->getSamples(), $data->getTargets());
{{< /highlight >}}

Nous pouvons ensuite faire des pr√©dictions sur de nouvelles transactions :

{{< highlight php >}}
<?php
$pipeline->predict(['FACTURE(S) CARTE XXX DU 230713 DECATHLON LYON']); // => ['shopping']
{{< /highlight >}}

Nous pouvons faire de m√™me avec `NaiveBayes`

{{< highlight php >}}
<?php
$estimator = new NaiveBayes();
$pipeline = new Pipeline($transformers, $estimator);
$pipeline->train($data->getSamples(), $data->getTargets());
$pipeline->predict(['...']);
{{< /highlight >}}

ou avec `KNearestNeighbors`

{{< highlight php >}}
<?php
$estimator = new KNearestNeighbors();
$pipeline = new Pipeline($transformers, $estimator);
$pipeline->train($data->getSamples(), $data->getTargets());
$pipeline->predict(['...']);
{{< /highlight >}}

### Calculer la justesse des classifications

Afin de d√©terminer **quel algorithme est le meilleur**, nous devons calculer sa pr√©cisions. Pour cela, il faut couper nos donn√©es en deux partie. Nous allons par exemple utiliser 90% de nos donn√©es pour entrainer l'algorithme et v√©rifier qu'il donne les bonnes pr√©visions pour les 10% de donn√©es restantes.

**PHP-ML** fourni la class `RandomSplit` pour cela :

{{< highlight php >}}
$data = new CsvDataset(__DIR__ . '/transactions.csv', 1, true, ',');
$split = new RandomSplit($data, 0.1); // 10% pour les tests
{{< /highlight >}}

Calculons ensuite la justesse de nos pr√©dictions avec la classe `Accuracy` :

{{< highlight php >}}
$pipeline = new Pipeline($transformers, $estimator);
$pipeline->train($split->getTrainSamples(), $split->getTrainLabels());
$predicted = $pipeline->predict($split->getTestSamples());

echo Accuracy::score($split->getTestLabels(), $predicted) . "\n";
{{< /highlight >}}

Avec les param√®tres par d√©faut de chaque algorithme, sur un jeu de donn√©es de 1700 transactions, j'obtiens les r√©sultats suivants :

<table class="table">
  <tr>
    <th>algorithme</th>
    <th>score</th>
    <th>pr√©dictions justes</th>
  <tr>
  <tr>
    <th>SVC</th>
    <td>0.43406593406593</td>
    <td>43%</td>
  </tr>
  <tr>
    <th>NaiveBayes</th>
    <td>0.95604395604396</td>
    <td class="good">95%</td>
  </tr>
  <tr>
    <th>KNearestNeighbors</th>
    <td>0.93956043956044</td>
    <td class="good">93%</td>
  </tr>
</table>

On obtiens seulement 43% de pr√©diction juste pour `SVC` mais plus de 90% avec `NaiveBayes` et `KNearestNeighbors`. C'est √† dire que ces deux algorithmes arrivent √† classer mes transactions dans la bonne cat√©gorie plus de 9 fois sur 10.

Voyons tout de m√™me si on ne peux pas am√©liorer les r√©sultats. L'algorithme `NaiveBayes` ne dispose d'aucun param√®tre, le seul moyen d'augmenter sa justesse de pr√©diction et d'augmenter la quantit√© et la qualit√© des donn√©es d'entrainement. Par contre `SVC` et `KNearestNeighbors` dispose tous les deux de param√®tres. Essayons d'en modifier les valeurs.

### Param√®trer les algorithmes

Nous pouvons modifier [de nombreux param√®tre sur l'algorithme **SVC**](https://php-ml.readthedocs.io/en/latest/machine-learning/classification/svc/).

Essayons d'int√©ragir avec le param√®tre `$cost` :

{{< highlight php >}}
<?php
new SVC(Kernel::RBF, $cost = 10);
{{< /highlight >}}

On voit tout de suite qu'on ratrappe largement les autres algorithmes, 99% de pr√©dictions justes c'est vraiment tr√®s bon.

<table class="table">
  <tr>
    <th>$cost</th>
    <th>score</th>
    <th>pr√©dictions justes</th>
  </tr>
  <tr>
    <td>1</td>
    <td>0.43406593406593</td>
    <td>43%</td>
  </tr>
  <tr>
    <td>10</td>
    <td>0.94767441860465</td>
    <td>95%</td>
  </tr>
  <tr>
    <td>100</td>
    <td>0.98837209302326</td>
    <td class="good">99%</td>
  </tr>
  <tr>
    <td>1000</td>
    <td>0.98837209302326</td>
    <td class="good">99%</td>
  </tr>
</table>

Essayons de voir si on peut faire la m√™me chose avec `KNearestNeighbors`. Nous pouvons modifier le param√®tre `$k` indiquant le nombre de plus proches voisins √† analyser.

{{< highlight php >}}
<?php
new KNearestNeighbors($k = 5);
{{< /highlight >}}

Malheureusement ici, on perd clairement en justesse.

<table class="table">
  <tr>
    <th>$k</th>
    <th>score</th>
    <th>pr√©dictions justes</th>
  </tr>
  <tr>
    <td>1</td>
    <td>0.93023255813953</td>
    <td>93%</td>
  </tr>
  <tr>
    <td>3</td>
    <td>0.92441860465116</td>
    <td>92%</td>
  </tr>
  <tr>
    <td>5</td>
    <td>0.90697674418605</td>
    <td class="bad">90%</td>
  </tr>
  <tr>
    <td>10</td>
    <td>0.88372093023256</td>
    <td class="bad">88%</td>
  </tr>
</table>

On peut √©galement modifier le param√®tre `$distanceMetric` avec l'un des diff√©rents type de distance disponible (Minkowski, Manhattan, Euclidean, Chebyshev), mais les pr√©dictions restes moins justes qu'avec **SVC**.

En conclusion, l'algorithme **SVC** avec un *cost* √† 100 est la solution qui offre les pr√©dictions les plus justes pour notre probl√®me.

## La r√©gression

La **r√©gression** permet de pr√©dire l'√©volution d'une variable quantitative en fonction d'une ou plusieurs autres variables. Il s'agit d'apprentissage supervis√©, on entra√Æne donc l'algorithme avec un jeu de donn√©es contenant l'√©volutions des valeurs pour la variables √† pr√©dire et les variables connues.

Le mod√®le de regression le plus simple est la **regression lin√©aire**. L'algorithme va placer dans un espace √† n-dimenssion des points correspondant aux tuples de variables, chaque dimenssion correspondant √† l'une des variables. Il trace ensuite une droite passant au plus pr√™t de tout les points. En fournissant n-1 variables, l'algorithme peut extrapoler la valeur de la variable manquante.

<div class="row">
  <div class="col-lg-6">
    <figure>
      <img src="/images/posts/2020/machine-learning/linear-regression.png" alt="R√©gression lin√©aire">
      <figcaption>R√©gression lin√©aire</figcaption>
    </figure>
  </div>
  <div class="col-lg-6">
    <figure>
      <img src="/images/posts/2020/machine-learning/non-linear-regression.png" alt="R√©gression non-lin√©aire">
      <figcaption>R√©gression non-lin√©aire</figcaption>
    </figure>
  </div>
</div>

Il est √©galement possible de faire de la regression non lin√©aire. Le principe est le m√™me que pour regression lin√©aire, sauf que la droite sera remplac√©e par une √©quation formant une courbe.

Si la regression lin√©aire sera plus juste pour des variables une ont une √©volution proportionnel, la regression non lin√©aire sera utilis√© pour des variables ayant une √©volution exponentionelle ou cyclique par exemple.

S'il est plut√¥t simple de faire ce travail sur du papier pour un probl√®me √† 2 variables, il devient complexe se passer de la machine √† partir de 3 variables. Je vous laisse vous imaginer une droite dans un espace √† 5, 6 ou 7 dimenssions.

![](/images/posts/2020/machine-learning/hard-maths.jpg)

### Cas d'usage

Prenons l'exemple d'un site d'annonce pour des locations de logement qui vous suggerait un prix en fonction des caract√©ristiques de votre logement en se basant sur les prix du march√©.

Pour simplifier notre probl√®me et facilit√© la repr√©sentation des r√©sultat, nous allons prendre en compte que deux variables, le loyer et la superficie en m<sup>2</sup>, sur des appartements dans une zone g√©ographique sans grosse disparit√© en terme de loyer.

```
18;520
78;860
18;465
53;635
...
```

On voit clairement ici une distribution lin√©aire malgr√© un l√©ger d√©but de courbe au dela 80m<sup>2</sup>.

<figure>
  <a href="/images/posts/2020/machine-learning/locations.svg">
    <img src="/images/posts/2020/machine-learning/locations.svg" alt="Donn√©es d'entrainement">
  </a>
  <figcaption>
    <span class="data-color a">Donn√©es d'entrainement</span>
  </figcaption>
</figure>

Essayons une regression lin√©aire avec l'algorithme [**LeastSquares**](https://php-ml.readthedocs.io/en/latest/machine-learning/regression/least-squares/) ([M√©thode des moindres carr√©s](https://fr.wikipedia.org/wiki/M%C3%A9thode_des_moindres_carr%C3%A9s)) :

{{< highlight php >}}
<?php
use Phpml\Dataset\CsvDataset;
use Phpml\Regression\LeastSquares;

$data = new CsvDataset(__DIR__ . '/locations.csv', 1, false, ';');
$regression = new LeastSquares();
$regression->train($data->getSamples(), $data->getTargets());
{{< /highlight >}}

Puis avec [**SVR**](https://php-ml.readthedocs.io/en/latest/machine-learning/regression/svr/) ([Machine √† vecteurs de support](https://fr.wikipedia.org/wiki/Machine_%C3%A0_vecteurs_de_support)) :

{{< highlight php >}}
<?php
use Phpml\Dataset\CsvDataset;
use Phpml\Regression\LeastSquares;

$data = new CsvDataset(__DIR__ . '/locations.csv', 1, false, ';');
$regression = new SVR(Kernel::LINEAR);
$regression->train($data->getSamples(), $data->getTargets());
{{< /highlight >}}

Si j'utilise ensuite la pr√©dictions sur plusieurs superficies inconnues, j'obtiens le resultat suivant :

{{< highlight php >}}
<?php
foreach ([15, 20, 50, 70, 100, 115, 140, 170, 200] as $v) {
    echo $regression->predict([$v]) . "\n";
}
{{< /highlight >}}

<table class="table">
  <tr>
    <th>m<sup>2</sup></th>
    <td>15</td>
    <td>20</td>
    <td>50</td>
    <td>70</td>
    <td>100</td>
    <td>115</td>
    <td>140</td>
    <td>170</td>
    <td>200</td>
  <tr>
  <tr>
    <th>‚Ç¨ <small>LeastSquares</small></th>
    <td>351</td>
    <td>409</td>
    <td>762</td>
    <td>997</td>
    <td>1350</td>
    <td>1527</td>
    <td>1821</td>
    <td>2173</td>
    <td>2526</td>
  <tr>
  <tr>
    <th>‚Ç¨ <small>SVR(LINEAR)</small></th>
    <td>355</td>
    <td>412</td>
    <td>757</td>
    <td>987</td>
    <td>1332</td>
    <td>1504</td>
    <td>1792</td>
    <td>2136</td>
    <td>2481</td>
  <tr>
</table>

Les deux alogrithmes donnnent deux droites l√©g√®rement diff√©rentes.

<figure>
  <a href="/images/posts/2020/machine-learning/locations-lineaire.svg">
    <img src="/images/posts/2020/machine-learning/locations-lineaire.svg" alt="R√©gressions lin√©aires">
  </a>
  <figcaption>
    <span class="data-color color-1">Donn√©es d'entrainement</span>
    <span class="data-color color-2">Donn√©es pr√©dites - LeastSquares</span>
    <span class="data-color color-3">Donn√©es pr√©dites - SVR(LINEAR)</span>
  </figcaption>
</figure>

Finalement on peut se rendre compte qu'au dela 80m<sup>2</sup> l'√©volution n'est peut √™tre pas si lin√©aire que √ßa. Essayons avec une **r√©gression non-lin√©aire**.

{{< highlight php >}}
<?php
$regression = new SVR(Kernel::POLYNOMIAL, 2);
$regression->train($data->getSamples(), $data->getTargets());

foreach ([15, 20, 50, 70, 100, 115, 140, 170, 200] as $v) {
    echo $regression->predict([$v]) . "\n";
}
{{< /highlight >}}

Il peut en effet sembler logique que sur les tr√®s grandes surfaces les prix au m<sup>2</sup> soit plus √©lev√©s car ces biens sont g√©n√©ralement plus rares et plus luxieux.

<figure>
  <a href="/images/posts/2020/machine-learning/locations-lineaire-polynomiale.svg">
    <img src="/images/posts/2020/machine-learning/locations-lineaire-polynomiale.svg" alt="R√©gression lin√©aire VS r√©gression non-lin√©aire">
  </a>
  <figcaption>
    <span class="data-color color-1">Donn√©es d'entrainement</span>
    <span class="data-color color-2">Donn√©es pr√©dites - SVR(POLYNOMIAL)</span>
    <span class="data-color color-3">Donn√©es pr√©dites - SVR(LINEAR)</span>
  </figcaption>
</figure>

Il nous faudrait d'avantage de donn√©es pour determiner quel mod√®le colle le plus √† la r√©alit√© mais nos regressions permettent tout de m√™me d'extrapoler avec plus ou moins de pr√©cisions les donn√©es manquantes.

Evidemment dans notre cas de loyer, il faudrait √©galement ajouter d'autres variables qui agissent sur le prix comme l'ann√©e de construction ou de r√©novation, le nombre de pi√®ces, peut √™tre un score en fonction des commodit√©s (ligne transport, commerces, √©coles, ...) ou de la localisation. Bref vous l'aurez compris, le plus difficile va √™tre de trouver ces variables et de leur attribuer des valeurs num√©riques.

### Calculer la justesse des r√©gressions

Pour calculer la pr√©cision d'un mod√®le, il faut couper nos donn√©es en deux partie (80% pour l'entrainement et 20% pour les tests par exemple). `StratifiedRandomSplit` permet une distribution homog√®ne entre donn√©es d'entrainement et  donn√©es de tests.

{{< highlight php >}}
<?php
$data = new CsvDataset(__DIR__ . '/locations.csv', 1, false, ';');
$split = new StratifiedRandomSplit($data, 0.2);
{{< /highlight >}}

On utilise la premi√®re partie pour entrainer notre algorithme, puis on compare les pr√©dictions sur la seconde partie avec les vrais r√©sultat :

{{< highlight php >}}
<?php
use Phpml\Metric\Regression;

function getMetrics($regression, Split $split): array {
    $regression->train($split->getTrainSamples(), $split->getTrainLabels());
    $predict = fn ($samples) => $regression->predict($samples);
    $predications = array_map($predict, $split->getTestSamples());
    $targets = $split->getTestLabels();

    return [
        'meanSqrErr' => Regression::meanSquaredError($predications, $targets),
        'meanSqrLogErr' => Regression::meanSquaredLogarithmicError($predications, $targets),
        'meanAbsErr' => Regression::meanAbsoluteError($predications, $targets),
        'medAbsErr' => Regression::medianAbsoluteError($predications, $targets),
        'maxError' => Regression::maxError($predications, $targets),
        'r2Score' => Regression::r2Score($predications, $targets),
    ];
}
{{< /highlight >}}

On fait cela avec chacune de nos r√©gressions :

{{< highlight php >}}
<?php
print_r(getMetrics(new LeastSquares(), $split));
print_r(getMetrics(new SVR(Kernel::LINEAR), $split));
print_r(getMetrics(new SVR(Kernel::POLYNOMIAL, 2), $split));
{{< /highlight >}}

Et cela nous donne des m√©triques nous aidant √† d√©terminer quelle r√©gression est la meilleure. Sur 100 it√©rations j'obtiens les m√©triques moyennes suivante :

<table class="table">
  <tr>
    <th>Algorithme</th>
    <th><abbr title="Erreur quadratique moyenne">Erreur quad. moy.</abbr></th>
    <th><abbr title="Erreur logarithmique quadratique moyenne">Erreur log. quad. moy.</abbr></th>
    <th><abbr title="Erreur absolue moyenne">Erreur absolue moy.</abbr></th>
    <th><abbr title="Erreur aboslue m√©dianne">Erreur absolue m√©diane</abbr></th>
    <th><abbr title="Erreur max">Erreur max</abbr></th>
    <th><abbr title="Score r2">Score r2</abbr></th>
  </tr>
  <tr>
    <th>LeastSquares</th>
    <td>38276</td>
    <td>0.0349</td>
    <td class="good">125</td>
    <td class="good">79</td>
    <td>889</td>
    <td>0.82</td>
  </tr>
  <tr>
    <th>SVR(LINEAR)</th>
    <td class="good">32062</td>
    <td class="good">0.0335</td>
    <td>131</td>
    <td>114</td>
    <td class="good">730</td>
    <td>0.82</td>
  </tr>
  <tr>
    <th>SVR(POLYNOM.)</th>
    <td>189201</td>
    <td>0.104</td>
    <td>340</td>
    <td>280</td>
    <td>1082</td>
    <td class="good">0.85</td>
  </tr>
</table>

On constate ici que les regressions lin√©aires ont donn√© des r√©sultats plus justes.

## Clustering

Le **clustering** permet de regrouper des √©l√©ments similaires dans des groupes homog√®nes. A la diff√©rence de la **classification**, il s'agit de d'**apprentissage non supervis√©**, les groupes ne sont pas connu √† l'avance, c'est √† l'algorithme de les d√©terminer. L'int√©ret n'est pas seulement de regrouper ces √©l√©ments, mais √©galement de faire √©merger des groupes √† partir de nos donn√©es.

Le clustering peut permettre par exemple de :

* Faire de la recommendation
* Segmenter des utilisateurs



https://www.youtube.com/watch?v=3FOrWMDL8CY
https://www.youtube.com/watch?v=aU7EWwLtiOg



<style type="text/css">
  .row {
    display: flex;
    flex-direction: row;
    align-items: flex-end;
  }

  figure {
    margin-bottom: 30px;
    text-align: center;
  }

  figcaption {
    text-align: center;
    font-size: 80%;
    line-height: 140%;
  }

  .table {
    width: 100%;
    margin-bottom: 30px;
  }

  .table th, .table td {
    text-align: right;
    border: 1px solid #ccc;
    padding: 0 10px;
  }

  .table th.good, .table td.good {
    background-color: #1AC580;
  }

  .table th.bad, .table td.bad {
    background-color: #ED4337;
  }

  .data-color {
    display: block;
  }

  .data-color::before {
    content: '';
    display: inline-block;
    width: 20px;
    height: 10px;
    margin-right: 5px;
    border: 1px solid #000;
  }

  .data-color.color-1::before { background-color: #bf6969; }
  .data-color.color-2::before { background-color: #69bf69; }
  .data-color.color-3::before { background-color: #6969bf; }

  .data-color.a::before { background-color: #D49D26; }
  .data-color.b::before { background-color: #7AB3E6; }
  .data-color.c::before { background-color: #589C75; }

</style>
